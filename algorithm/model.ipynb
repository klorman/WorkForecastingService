{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import transformers as ppb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = pd.read_excel(\"1_Многоквартирные дома с технико-экономическими характеристиками.xlsx\")\n",
    "table_2 = pd.read_excel(\"2_Инциденты,_зарегистрированные_на_объектах_городского_хозяйства.xlsx\")\n",
    "table_3 = pd.read_excel(\"3_Работы по капитальному ремонту, проведенные в многоквартирных домах.xlsx\")\n",
    "table_4_1 = pd.read_excel(\"4_Виды работ по капитальному ремонту многоквартирных домов.xlsx\")\n",
    "table_4_2 = pd.read_excel(\"4_Виды работ по содержанию и ремонту общего имущества многоквартирных домов.xlsx\")\n",
    "table_5 = pd.read_excel(\"5_Типы событий, регистрируемых по типу объекта многоквартирный дом.xlsx\")\n",
    "\n",
    "table_1 = table_1.drop(labels=[0], axis=0)\n",
    "table_4_1 = table_4_1.drop(labels=[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All date make date\n",
    "#table 2\n",
    "table_2[\"Дата создания во внешней системе\"] = pd.to_datetime(table_2[\"Дата создания во внешней системе\"], \n",
    "                                                             format = \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "                                                             errors = 'coerce')\n",
    "table_2[\"Дата закрытия\"] = pd.to_datetime(table_2[\"Дата создания во внешней системе\"], \n",
    "                                          format = \"%Y-%m-%d %H:%M:%S.%f\",\n",
    "                                          errors = 'coerce')\n",
    "#table 3\n",
    "table_3[\"PLAN_DATE_START\"] = pd.to_datetime(table_3[\"PLAN_DATE_START\"],\n",
    "                                            #format=\"%Y.%m.%d\",\n",
    "                                            errors='coerce')\n",
    "table_3[\"PLAN_DATE_END\"] = pd.to_datetime(table_3[\"PLAN_DATE_END\"],\n",
    "                                            #format=\"%Y.%m.%d\",\n",
    "                                            errors='ignore')\n",
    "table_3[\"FACT_DATE_START\"] = pd.to_datetime(table_3[\"FACT_DATE_START\"],\n",
    "                                            #format=\"%Y.%m.%d\",\n",
    "                                            errors='ignore')\n",
    "table_3[\"FACT_DATE_END\"] = pd.to_datetime(table_3[\"FACT_DATE_END\"],\n",
    "                                            #format=\"%Y.%m.%d\",\n",
    "                                            errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function standartization\n",
    "def StandardCol(table: pd.DataFrame, name: str):\n",
    "    table[name] = table[name].astype(float)\n",
    "    if table_1[name].isna().sum() != 0:\n",
    "        table[name] = table[name].fillna(0)\n",
    "    return stats.zscore(table[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 958kB/s]\n",
      "C:\\Users\\Klorman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Klorman\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 6.99kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 483/483 [00:00<00:00, 161kB/s]\n"
     ]
    }
   ],
   "source": [
    "#BERT tokenizer\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "# удаление нахер вссего NaN дерьма\n",
    "for count, elem in enumerate(table_2[\"Наименование\"].isna()):\n",
    "    if elem:\n",
    "        table_2 = table_2.drop(labels=[count], axis=0)\n",
    "table_2[\"Наименование\"].isna().sum()\n",
    "\n",
    "# apply tokenizator\n",
    "df = table_2[\"Наименование\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "# find max_len\n",
    "max_len = 0\n",
    "for i in df.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "if max_len % 2 == 1:\n",
    "    max_len += 1\n",
    "\n",
    "# add <pad> symbol\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in df.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = []\n",
    "y_batch = []\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, table_1, table_2, table_3, padded = None):\n",
    "        super().__init__()\n",
    "        # make Bert Model for make embedding requests\n",
    "        model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "        # Load tokenizer\n",
    "        self.tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "        self.features_table_1 = [ \"COL_756\", \"COL_758\", \"COL_759\", \"COL_760\", \"COL_761\", \"COL_762\", \n",
    "                              \"COL_763\", \"COL_764\", \"COL_769\", \"COL_770\", \"COL_771\", \"COL_772\", \n",
    "                              \"COL_781\", \"COL_3363\"]\n",
    "        self.features_table_2 = [ \"Дата закрытия\", \"Дата создания во внешней системе\"]\n",
    "        self.features_table_3 = [\"WORK_NAME\", \"PLAN_DATE_START\", \"FACT_DATE_START\"] # можно ещё \"PLAN_DATE_START\", \"FACT_DATE_START\"\n",
    "        self.unique_unom = list(set(table_1[\"COL_782\"].apply(int)) & set(table_2[\"unom\"].apply(int)) & set(table_3[\"UNOM\"].apply(int)))\n",
    "        self.dict_all_works = {name: count for count,name in enumerate(set(table_3[\"WORK_NAME\"]))}\n",
    "        self.dict_all_works_zero = {name: 0 for name in set(table_3[\"WORK_NAME\"])}\n",
    "        self.table_1 = table_1\n",
    "        self.table_2 = table_2\n",
    "        self.table_3 = table_3\n",
    "        self.padded = padded #pd.Dself.encoder_text(table_2[\"Наименование\"])\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.unique_unom)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        unom = self.unique_unom[idx]\n",
    "        # idx = unom\n",
    "        # get needed table\n",
    "\n",
    "        table_1_unom = table_1.loc[(table_1[\"COL_782\"].apply(int)==unom)]\n",
    "        table_2_unom = table_2.loc[(table_2[\"unom\"].apply(int)==unom)]\n",
    "        table_3_unom = table_3.loc[(table_3[\"UNOM\"].apply(int)==unom)]\n",
    "\n",
    "        work_unom_time = self.get_difference_time_work(table_3_unom)\n",
    "\n",
    "        table_3_unom['WORK_NAME'] = table_3_unom['WORK_NAME'].apply((lambda x: self.dict_all_works[x]))\n",
    "        # choose needed coloumn in table\n",
    "        table_1_res = self.get_table(table_1_unom, self.features_table_1).apply(float).to_numpy()\n",
    "        table_2_res = self.get_table(table_2_unom, self.features_table_2)\n",
    "        table_2_res = self.convert_date(table_2_res)\n",
    "        #print(\"table_2_res\", table_2_res[0][0])\n",
    "        table_3_res = self.get_table(table_3_unom, self.features_table_3)\n",
    "        #print(\"table_3_res\", table_3_res)\n",
    "        table_2_text = self.get_padded_sent(unom)\n",
    "        #print(\"table_2_text\", table_2_text)\n",
    "        # get right result\n",
    "        print(work_unom_time)\n",
    "        #work_unom_time = self.get_difference_time_work(table_3_unom)\n",
    "        #print(table_1_res, table_2_res, table_3_res)\n",
    "        X_batch.append((table_1_res, table_2_res, table_3_res, table_2_text))\n",
    "        y_batch.append(pd.DataFrame(work_unom_time).to_numpy())\n",
    "        return  0,0#torch.tensor((table_1_res, table_2_res, table_3_res, table_2_text)), torch.tensor(work_unom_time)\n",
    "    \n",
    "\n",
    "    def convert_date(self, table):\n",
    "        new_t = {\"day_beg\": [], \"month_beg\": [], \"year_beg\": [], \"day_end\": [], \"month_end\": [], \"year_end\": []}\n",
    "        new_t[\"day_beg\"] = table[\"Дата создания во внешней системе\"].dt.day.to_numpy()\n",
    "        new_t[\"month_beg\"] = table[\"Дата создания во внешней системе\"].dt.month.to_numpy()\n",
    "        new_t[\"year_beg\"]  = table[\"Дата создания во внешней системе\"].dt.year.to_numpy()\n",
    "        new_t[\"hour_beg\"]  = table[\"Дата создания во внешней системе\"].dt.hour.to_numpy()\n",
    "        new_t[\"minute_beg\"]  = table[\"Дата создания во внешней системе\"].dt.minute.to_numpy()\n",
    "        new_t[\"day_end\"] = table[\"Дата закрытия\"].dt.day.to_numpy()\n",
    "        new_t[\"month_end\"] = table[\"Дата закрытия\"].dt.month.to_numpy()\n",
    "        new_t[\"year_end\"] = table[\"Дата закрытия\"].dt.year.to_numpy()\n",
    "        new_t[\"hour_end\"] = table[\"Дата закрытия\"].dt.hour.to_numpy()\n",
    "        new_t[\"minute_end\"] = table[\"Дата закрытия\"].dt.minute.to_numpy()\n",
    "        return pd.DataFrame(new_t)\n",
    "    \n",
    "\n",
    "    def get_padded_sent(self, unom: int):\n",
    "        index = self.table_2[self.table_2['unom'].apply(int) == unom].index \n",
    "        pad_sent = []\n",
    "        for idx in index:\n",
    "            pad_sent.append(self.padded[idx])\n",
    "        return np.asarray(pad_sent)\n",
    "\n",
    "\n",
    "    def get_table(self, table, features):\n",
    "        dict_new_table = {name: [] for name in features}\n",
    "        for name in features:\n",
    "            dict_new_table[name] = table[name]\n",
    "        return pd.DataFrame(dict_new_table)\n",
    "    \n",
    "\n",
    "    def get_difference_time_work(self, table): # передаем данные по конкретному уному\n",
    "        # get list all work\n",
    "        work_unom_time = self.dict_all_works_zero\n",
    "        # get date fact and plan work\n",
    "        fact_beg_day = table[\"FACT_DATE_START\"].dt.day\n",
    "        fact_beg_month = table[\"FACT_DATE_START\"].dt.month\n",
    "        fact_beg_year  = table[\"FACT_DATE_START\"].dt.year\n",
    "        plan_beg_day = table[\"PLAN_DATE_START\"].dt.day\n",
    "        plan_beg_month = table[\"PLAN_DATE_START\"].dt.month\n",
    "        plan_beg_year = table[\"PLAN_DATE_START\"].dt.year\n",
    "        # compute result difference \n",
    "        result = ((plan_beg_year - fact_beg_year) * 365 + (plan_beg_month - fact_beg_month) * 30 + (plan_beg_day - fact_beg_day)).to_numpy()\n",
    "        # compute mean time deviation for all works\n",
    "        for count, name in enumerate(table[\"WORK_NAME\"]):\n",
    "            work_unom_time[name] =  (work_unom_time[name] + result[count]) / 2\n",
    "        values = []\n",
    "        for key in work_unom_time.keys():\n",
    "            values.append(work_unom_time[key])\n",
    "        return values\n",
    "    \n",
    "\n",
    "    def encoder_text(self, coloumn_text):\n",
    "        # apply tokenizer\n",
    "        with torch.no_grad():\n",
    "            coloumn = coloumn_text.apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "        # <pad>\n",
    "        max_len = 0\n",
    "        for i in coloumn.values:\n",
    "            if len(i) > max_len:\n",
    "                max_len = len(i)\n",
    "\n",
    "        if max_len % 2 == 1:\n",
    "            max_len += 1\n",
    "\n",
    "        padded = np.array([i + [0]*(max_len-len(i)) for i in coloumn.values])\n",
    "\n",
    "        return pd.DataFrame(padded)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1)\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-np.log(10000.0)) / dim_model) \n",
    "\n",
    "        # PE(pos, 2i) = = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "\n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\", pos_encoding)\n",
    "    \n",
    "\n",
    "    def forward(self, token_embedding):\n",
    "        output = self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Каждая заявка вносит свой вклад в приближение капитального ремонта\n",
    "class ProcessRequestsNN(nn.Module):\n",
    "    def __init__(self, num_features: int, num_add_features: int, hidden_dim: int = 64, emb_dim: int = 1024, modelBERT = None, num_requests: int = 19,\n",
    "                 dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_size = emb_dim\n",
    "        self.num_requests = num_requests\n",
    "        self.output_conv = self.__compute_output() + num_add_features\n",
    "        # Layers\n",
    "        # Embedding\n",
    "        if modelBERT is None:\n",
    "            # make Bert Model for make embedding requests\n",
    "            model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "            self.embed = model_class.from_pretrained(pretrained_weights)\n",
    "            self.dimBERT = 768\n",
    "        else:\n",
    "            self.embed = modelBERT\n",
    "            self.dimBERT = 768\n",
    "        \n",
    "        self.conv_1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=5, stride=2, padding=4)\n",
    "        self.max_pool_1 = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool_2 = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_3 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool_3 = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_4 = nn.Conv1d(in_channels=32, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        self.max_pool_4 = nn.MaxPool1d(kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "\n",
    "        self.embed_after_conv = nn.Embedding(self.output_conv , self.embedding_size)\n",
    "        self.linear_1 = nn.Linear(self.output_conv, int(self.embedding_size/2))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_2 = nn.Linear(int(self.embedding_size/2), int(self.embedding_size/8))\n",
    "        self.linear_3 = nn.Linear(int(self.embedding_size/8), self.num_requests)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.batch_norm = nn.BatchNorm1d(self.output_conv)\n",
    "\n",
    "    \n",
    "    def forward(self, in_data, in_data_2):\n",
    "        attention_mask = torch.tensor(np.where(in_data != 0, 1, 0))\n",
    "        #embed = model_class.from_pretrained(pretrained_weights)\n",
    "        with torch.no_grad():\n",
    "            out = self.embed(in_data, attention_mask=attention_mask)\n",
    "\n",
    "        out = out[0].reshape(out[0].shape[0], out[0].shape[1]*out[0].shape[2]).unsqueeze(1)\n",
    "        print(\"out.shape\", out.shape)\n",
    "\n",
    "        # Apply conv layer\n",
    "        out = self.conv_1(out)\n",
    "        out = self.max_pool_1(out)\n",
    "        out = self.conv_2(out)\n",
    "        out = self.max_pool_2(out)\n",
    "        out = self.conv_3(out)\n",
    "        out = self.max_pool_3(out)\n",
    "        out = self.conv_4(out)\n",
    "        out = self.max_pool_4(out)\n",
    "        out = self.flatten(out)\n",
    "\n",
    "        # concatenate date and name requests\n",
    "        out = torch.concatenate(((out, in_data_2.permute(1,0))), dim=1)\n",
    "        out = out.unsqueeze(0)\n",
    "        # Apply Fully connected layer\n",
    "        #out = self.batch_norm(out)\n",
    "        #out = self.embed_after_conv(out.Lomnn)\n",
    "        out = self.linear_1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear_3(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "    def __compute_output(self):\n",
    "        dim1 = 26882 \n",
    "        dim_out = dim1\n",
    "        return dim_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "buff_out = 0\n",
    "buff_h = 0\n",
    "buff_c = 0\n",
    "buff_cat = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeResultNN(nn.Module):\n",
    "    def __init__(self, num_features_req: int, num_features_cat: int = 14, num_output: int = 19,\n",
    "                 emb_size: int = 128, hidden_dim: int = 64, dropout: float = 0.1, num_add_features: int = 10,\n",
    "                 num_features_date_cup:int = 4):\n",
    "        super().__init__()\n",
    "        self.num_features_cat = num_features_cat\n",
    "        self.emb_size = emb_size\n",
    "        self.hid_dim = hidden_dim\n",
    "\n",
    "        self.process_request = ProcessRequestsNN(num_features=num_features_req,\n",
    "                                                 num_add_features=num_add_features)\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size = num_output,\n",
    "                           hidden_size = self.hid_dim,\n",
    "                           num_layers = 1, # may be 4 or 5 поставить\n",
    "                           dropout=dropout,\n",
    "                           bidirectional=True) #через lstm прогоняем все запросы получаем скрытое представление\n",
    "        self.linear_1 = nn.Linear(num_features_cat + num_output, self.hid_dim)\n",
    "        self.linear_2 = nn.Linear(self.hid_dim, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "\n",
    "    def forward(self, in_data_cat, in_data_request, in_data_date):\n",
    "        # proccess request\n",
    "        out_req = self.process_request(in_data_request, in_data_date).squeeze(0)\n",
    "        #out_req, (hid, cell) = self.rnn(out_req)\n",
    "        # concatenate information\n",
    "        multiply = torch.tensor([1 for i in range(19)])\n",
    "        for i in out_req:\n",
    "            multiply = torch.multiply(multiply, i)\n",
    "        print(multiply.size())\n",
    "        data_concat = torch.concatenate((multiply, in_data_cat), dim=0)\n",
    "\n",
    "        # proccess specifications and out other model\n",
    "        out = self.linear_1(data_concat.float())\n",
    "        out = self.relu(out)\n",
    "        out = self.linear_2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 70\n",
    "NUM_FEATURES_REQ = MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|██████████| 268M/268M [00:23<00:00, 11.5MB/s] \n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\Klorman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\torch\\nn\\modules\\rnn.py:70: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# make model\n",
    "model = ComputeResultNN(num_features_req=NUM_FEATURES_REQ,\n",
    "                        num_features_cat=15,\n",
    "                        num_output=19,\n",
    "                        num_add_features=10,\n",
    "                        num_features_date_cup=7)\n",
    "loss_fn = nn.L1Loss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получение даты и ее разности для запросов\n",
    "def get_data_date(table):\n",
    "    days_close = table[\"day_end\"]\n",
    "\n",
    "    time_perform_days = table[\"day_end\"].to_numpy() - table[\"day_beg\"]\n",
    "    time_perform_month = table[\"month_end\"].to_numpy() - table[\"month_beg\"].to_numpy()\n",
    "    time_perform_year = table[\"year_end\"].to_numpy() - table[\"year_beg\"].to_numpy()\n",
    "    time_perform_hour = table[\"hour_end\"].to_numpy() - table[\"hour_beg\"].to_numpy()\n",
    "    time_perform_minute = table[\"minute_end\"].to_numpy() - table[\"minute_beg\"].to_numpy()\n",
    "\n",
    "    arr_times = [table[\"day_beg\"].to_numpy(), table[\"month_beg\"].to_numpy(), table[\"year_beg\"].to_numpy(), \n",
    "                 table[\"hour_beg\"].to_numpy(), table[\"minute_beg\"].to_numpy(),time_perform_days,\n",
    "                 time_perform_month, time_perform_year,\n",
    "                 time_perform_hour,time_perform_minute]\n",
    "    return torch.tensor(arr_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вычисление ответа\n",
    "def compute_y(table):\n",
    "    d = {f'{i}': 0 for i in range(19)}\n",
    "    d_exists = {f'{i}': 0 for i in range(19)}\n",
    "    d_out = {}\n",
    "    fact_beg_day = table[\"FACT_DATE_START\"].dt.day.to_numpy()\n",
    "    fact_beg_month = table[\"FACT_DATE_START\"].dt.month.to_numpy()\n",
    "    fact_beg_year  = table[\"FACT_DATE_START\"].dt.year.to_numpy()\n",
    "    plan_beg_day = table[\"PLAN_DATE_START\"].dt.day.to_numpy()\n",
    "    plan_beg_month = table[\"PLAN_DATE_START\"].dt.month.to_numpy()\n",
    "    plan_beg_year = table[\"PLAN_DATE_START\"].dt.year.to_numpy()\n",
    "    result = ((plan_beg_year - fact_beg_year) * 365 + (plan_beg_month - fact_beg_month) * 30 + (plan_beg_day - fact_beg_day))\n",
    "    \n",
    "    table = table.to_numpy()\n",
    "    for count, name in enumerate(table):\n",
    "        d[f\"{name[0]}\"] = (d[f\"{name[0]}\"] + result[count]) / 2\n",
    "        d_exists[f\"{name[0]}\"] = 1\n",
    "    for k in d.keys():\n",
    "        if d_exists[k] == 1:\n",
    "            d_out[k] = d[k]\n",
    "    return d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Klorman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, -12.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "{'3': -12.5}\n",
      "torch.Size([193, 70]) torch.Size([10, 193])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Klorman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\ipykernel_launcher.py:15: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Klorman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\ipykernel_launcher.py:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([193, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, 0, -12.5, -2.0, 0, -125.5, 0, -20.5, 0, -2.0, 0, 43.0, -20.5, -20.5, 0, -17.0, 0.5, -2.0]\n",
      "{'4': -2.0, '6': -125.5, '8': -20.5, '10': -2.0, '12': 43.0, '13': -20.5, '14': -20.5, '16': -17.0, '17': 0.5, '18': -2.0}\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([141, 70]) torch.Size([10, 141])\n",
      "out.shape torch.Size([141, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, 16.0, -12.5, -2.0, 0, -125.5, 0, -20.5, 0, -2.0, 0, 43.0, -20.5, -20.5, 0, -17.0, -65.25, -2.0]\n",
      "{'2': 16.0, '17': -65.5}\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, 16.0, -12.5, -2.0, 0, -125.5, 0, -20.5, 0, -2.0, 0.0, 43.0, -20.5, -20.5, 0, -17.0, -65.25, -2.0]\n",
      "{'11': 0.0}\n",
      "torch.Size([116, 70]) torch.Size([10, 116])\n",
      "out.shape torch.Size([116, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, 16.0, -142.75, -2.0, 0, -125.5, 0, -20.5, 0, -2.0, 0.0, 43.0, -20.5, -20.5, 0, -17.0, -65.25, -2.0]\n",
      "{'3': -136.5}\n",
      "torch.Size([439, 70]) torch.Size([10, 439])\n",
      "out.shape torch.Size([439, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, -47.5, -142.75, -2.0, 0, -125.5, 0, -20.5, 0, -2.0, 0.0, 43.0, -20.5, -20.5, 0, -17.0, -65.25, -2.0]\n",
      "{'2': -55.5}\n",
      "torch.Size([158, 70]) torch.Size([10, 158])\n",
      "out.shape torch.Size([158, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, -47.5, -142.75, -2.0, -14.0, -125.5, 0, -20.5, 0, 0.5, 0.0, 51.0, -20.5, -20.5, 0, -17.0, -65.25, 0.5]\n",
      "{'5': -14.0, '10': 1.5, '12': 29.5, '18': 1.5}\n",
      "torch.Size([400, 70]) torch.Size([10, 400])\n",
      "out.shape torch.Size([400, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([400, 70]) torch.Size([10, 400])\n",
      "out.shape torch.Size([400, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([400, 70]) torch.Size([10, 400])\n",
      "out.shape torch.Size([400, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([400, 70]) torch.Size([10, 400])\n",
      "out.shape torch.Size([400, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, -47.5, -142.75, -2.0, -14.0, -125.5, 0, -20.5, -57.0, 0.5, 0.0, 51.0, -20.5, -20.5, 0, -17.0, -65.25, 0.5]\n",
      "{'9': -57.0}\n",
      "torch.Size([421, 70]) torch.Size([10, 421])\n",
      "out.shape torch.Size([421, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, -105.25, -142.75, 0.5, -23.5, -125.5, 0, -20.5, -57.0, 8.75, 0.0, 50.0, -55.25, -10.25, 0, -24.0, -65.25, 8.75]\n",
      "{'2': -81.5, '4': 1.5, '5': -16.5, '10': 8.5, '12': 24.5, '13': -45.0, '14': 0.0, '16': -15.5, '18': 8.5}\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([342, 70]) torch.Size([10, 342])\n",
      "out.shape torch.Size([342, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, -105.25, -142.75, 8.25, -23.5, -125.5, 0, 131.75, -57.0, 8.75, 0.0, 63.0, 114.375, 136.875, 0, 130.0, -65.25, 8.75]\n",
      "{'4': 8.0, '8': 142.0, '12': 38.0, '13': 142.0, '14': 142.0, '16': 142.0}\n",
      "torch.Size([183, 70]) torch.Size([10, 183])\n",
      "out.shape torch.Size([183, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([183, 70]) torch.Size([10, 183])\n",
      "out.shape torch.Size([183, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([183, 70]) torch.Size([10, 183])\n",
      "out.shape torch.Size([183, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([183, 70]) torch.Size([10, 183])\n",
      "out.shape torch.Size([183, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([183, 70]) torch.Size([10, 183])\n",
      "out.shape torch.Size([183, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([183, 70]) torch.Size([10, 183])\n",
      "out.shape torch.Size([183, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, 0, -120.625, -142.75, 2.125, -23.5, -125.5, 0, 65.875, -57.0, -107.625, 83.0, 56.0, 12.1875, 68.4375, 0, 49.5, -65.25, -107.625]\n",
      "{'2': -68.0, '4': -2.0, '8': 0.0, '10': -112.0, '11': 83.0, '12': 24.5, '13': -45.0, '14': 0.0, '16': -15.5, '18': -112.0}\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([615, 70]) torch.Size([10, 615])\n",
      "out.shape torch.Size([615, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -66.8125, -142.75, -20.9375, -23.5, -125.5, 0, 65.875, -57.0, -107.625, 83.0, 90.0, 12.1875, 68.4375, 0, 17.25, -65.25, -107.625]\n",
      "{'1': -7.5, '2': -6.5, '4': -22.0, '12': 62.0, '16': -7.5}\n",
      "torch.Size([203, 70]) torch.Size([10, 203])\n",
      "out.shape torch.Size([203, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([203, 70]) torch.Size([10, 203])\n",
      "out.shape torch.Size([203, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([203, 70]) torch.Size([10, 203])\n",
      "out.shape torch.Size([203, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([203, 70]) torch.Size([10, 203])\n",
      "out.shape torch.Size([203, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([203, 70]) torch.Size([10, 203])\n",
      "out.shape torch.Size([203, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -39.90625, -142.75, 36.53125, -23.5, -125.5, 0, 49.9375, -57.0, -107.625, 185.5, 107.0, 23.09375, 51.21875, 0, 17.25, -65.25, -107.625]\n",
      "{'2': -6.5, '4': 47.0, '8': 17.0, '11': 144.0, '12': 62.0, '13': 17.0, '14': 17.0}\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([211, 70]) torch.Size([10, 211])\n",
      "out.shape torch.Size([211, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -39.90625, -142.75, 18.265625, -23.5, -125.5, 0, 70.96875, -57.0, -107.625, 185.5, 92.5, 44.046875, 71.609375, 0, 17.25, -65.25, -107.625]\n",
      "{'4': 0.0, '8': 46.0, '12': 39.0, '13': 32.5, '14': 46.0}\n",
      "torch.Size([153, 70]) torch.Size([10, 153])\n",
      "out.shape torch.Size([153, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([153, 70]) torch.Size([10, 153])\n",
      "out.shape torch.Size([153, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([153, 70]) torch.Size([10, 153])\n",
      "out.shape torch.Size([153, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([153, 70]) torch.Size([10, 153])\n",
      "out.shape torch.Size([153, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([153, 70]) torch.Size([10, 153])\n",
      "out.shape torch.Size([153, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -39.90625, -142.75, 92.6328125, -23.5, -125.5, 0, 70.96875, -57.0, -107.625, 185.5, 151.75, 108.5234375, 122.3046875, 0, 17.25, -65.25, -107.625]\n",
      "{'4': 83.5, '12': 105.5, '13': 86.5, '14': 86.5}\n",
      "torch.Size([102, 70]) torch.Size([10, 102])\n",
      "out.shape torch.Size([102, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([102, 70]) torch.Size([10, 102])\n",
      "out.shape torch.Size([102, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([102, 70]) torch.Size([10, 102])\n",
      "out.shape torch.Size([102, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([102, 70]) torch.Size([10, 102])\n",
      "out.shape torch.Size([102, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -39.90625, -40.6875, 92.6328125, -23.5, -125.5, 0, 70.96875, -57.0, -107.625, 185.5, 151.75, 108.5234375, 122.3046875, 0, 17.25, -65.25, -107.625]\n",
      "{'3': -5.0}\n",
      "torch.Size([394, 70]) torch.Size([10, 394])\n",
      "out.shape torch.Size([394, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -39.90625, -175.171875, 92.6328125, -23.5, -125.5, 0, 70.96875, -57.0, -107.625, 185.5, 151.75, 108.5234375, 122.3046875, 0, 17.25, -65.25, -107.625]\n",
      "{'3': -165.0}\n",
      "torch.Size([281, 70]) torch.Size([10, 281])\n",
      "out.shape torch.Size([281, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -76.453125, -175.171875, 92.6328125, -23.5, -125.5, 0, 70.96875, -57.0, -107.625, 185.75, 151.75, 108.5234375, 122.3046875, 0, 17.25, -65.25, -107.625]\n",
      "{'2': -56.5, '11': 93.0}\n",
      "torch.Size([194, 70]) torch.Size([10, 194])\n",
      "out.shape torch.Size([194, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([194, 70]) torch.Size([10, 194])\n",
      "out.shape torch.Size([194, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -91.2265625, -175.171875, 1.81640625, -77.25, -125.5, 0, 70.96875, -57.0, -107.625, 39.875, 151.75, 108.5234375, 122.3046875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'2': -53.0, '4': -44.5, '5': -65.5, '11': -53.0, '15': -54.5, '17': 0.0, '18': -51.0}\n",
      "torch.Size([63, 70]) torch.Size([10, 63])\n",
      "out.shape torch.Size([63, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([63, 70]) torch.Size([10, 63])\n",
      "out.shape torch.Size([63, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([63, 70]) torch.Size([10, 63])\n",
      "out.shape torch.Size([63, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([63, 70]) torch.Size([10, 63])\n",
      "out.shape torch.Size([63, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([63, 70]) torch.Size([10, 63])\n",
      "out.shape torch.Size([63, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([63, 70]) torch.Size([10, 63])\n",
      "out.shape torch.Size([63, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([63, 70]) torch.Size([10, 63])\n",
      "out.shape torch.Size([63, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -115.61328125, -175.171875, -13.091796875, -77.25, -125.5, 0, 184.984375, -57.0, -107.625, 102.4375, 128.375, 83.76171875, 210.65234375, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'2': -70.0, '4': -14.0, '8': 149.5, '11': 82.5, '12': 52.5, '13': 29.5, '14': 149.5}\n",
      "torch.Size([171, 70]) torch.Size([10, 171])\n",
      "out.shape torch.Size([171, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([171, 70]) torch.Size([10, 171])\n",
      "out.shape torch.Size([171, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([171, 70]) torch.Size([10, 171])\n",
      "out.shape torch.Size([171, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([171, 70]) torch.Size([10, 171])\n",
      "out.shape torch.Size([171, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([171, 70]) torch.Size([10, 171])\n",
      "out.shape torch.Size([171, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([171, 70]) torch.Size([10, 171])\n",
      "out.shape torch.Size([171, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([171, 70]) torch.Size([10, 171])\n",
      "out.shape torch.Size([171, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -115.61328125, -10.9482421875, -13.091796875, -77.25, -125.5, 0, 184.984375, -57.0, -107.625, 102.4375, 128.375, 83.76171875, 210.65234375, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([298, 70]) torch.Size([10, 298])\n",
      "out.shape torch.Size([298, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -115.61328125, -0.68426513671875, -13.091796875, -77.25, -125.5, 0, 184.984375, -57.0, -107.625, 102.4375, 128.375, 83.76171875, 210.65234375, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([242, 70]) torch.Size([10, 242])\n",
      "out.shape torch.Size([242, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -115.61328125, -0.042766571044921875, -13.091796875, -77.25, -125.5, 0, 184.984375, -57.0, -107.625, 102.4375, 128.375, 83.76171875, 210.65234375, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([289, 70]) torch.Size([10, 289])\n",
      "out.shape torch.Size([289, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -115.61328125, -0.002672910690307617, -13.091796875, -77.25, -125.5, 0, 184.984375, -57.0, -107.625, 102.4375, 128.375, 83.76171875, 210.65234375, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([250, 70]) torch.Size([10, 250])\n",
      "out.shape torch.Size([250, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -115.61328125, 33.90616647154093, -13.091796875, -77.25, -125.5, 0, 184.984375, -57.0, -107.625, 102.4375, 128.375, 83.76171875, 210.65234375, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 33.90625}\n",
      "torch.Size([213, 70]) torch.Size([10, 213])\n",
      "out.shape torch.Size([213, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, 33.90616647154093, -21.0458984375, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'2': -68.0, '4': -14.5, '8': 39.5, '11': 77.5, '12': -4.5, '13': 3.5, '14': 39.5}\n",
      "torch.Size([188, 70]) torch.Size([10, 188])\n",
      "out.shape torch.Size([188, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([188, 70]) torch.Size([10, 188])\n",
      "out.shape torch.Size([188, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([188, 70]) torch.Size([10, 188])\n",
      "out.shape torch.Size([188, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([188, 70]) torch.Size([10, 188])\n",
      "out.shape torch.Size([188, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([188, 70]) torch.Size([10, 188])\n",
      "out.shape torch.Size([188, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([188, 70]) torch.Size([10, 188])\n",
      "out.shape torch.Size([188, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([188, 70]) torch.Size([10, 188])\n",
      "out.shape torch.Size([188, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, 4.238270808942616, -21.0458984375, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([116, 70]) torch.Size([10, 116])\n",
      "out.shape torch.Size([116, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -6.027527018610272, -21.0458984375, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': -6.09375}\n",
      "torch.Size([300, 70]) torch.Size([10, 300])\n",
      "out.shape torch.Size([300, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -0.011772513708223187, -21.0458984375, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([250, 70]) torch.Size([10, 250])\n",
      "out.shape torch.Size([250, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -0.0007357821067639492, -21.0458984375, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([183, 70]) torch.Size([10, 183])\n",
      "out.shape torch.Size([183, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -1.6875459863816729, -21.0458984375, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': -1.6875}\n",
      "torch.Size([425, 70]) torch.Size([10, 425])\n",
      "out.shape torch.Size([425, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -84.02636790603722, -21.0458984375, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': -84.0}\n",
      "torch.Size([367, 70]) torch.Size([10, 367])\n",
      "out.shape torch.Size([367, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -18.751647994127325, -21.0458984375, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': -13.5}\n",
      "torch.Size([212, 70]) torch.Size([10, 212])\n",
      "out.shape torch.Size([212, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -18.751647994127325, -9.02294921875, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'4': 1.5}\n",
      "torch.Size([51, 70]) torch.Size([10, 51])\n",
      "out.shape torch.Size([51, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -1.1719779996329578, -9.02294921875, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([295, 70]) torch.Size([10, 295])\n",
      "out.shape torch.Size([295, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -18.07324862497706, -9.02294921875, -77.25, -125.5, 0, 131.9921875, -57.0, -107.625, 128.71875, 59.6875, 45.380859375, 144.826171875, -54.5, 17.25, -32.625, -104.8125]\n",
      "{'3': -18.0}\n",
      "torch.Size([195, 70]) torch.Size([10, 195])\n",
      "out.shape torch.Size([195, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -18.07324862497706, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 128.71875, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'6': -25.0, '12': 13.0, '17': -22.0}\n",
      "torch.Size([96, 70]) torch.Size([10, 96])\n",
      "out.shape torch.Size([96, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([96, 70]) torch.Size([10, 96])\n",
      "out.shape torch.Size([96, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([96, 70]) torch.Size([10, 96])\n",
      "out.shape torch.Size([96, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -19.129578039061066, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 128.71875, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': -18.0}\n",
      "torch.Size([204, 70]) torch.Size([10, 204])\n",
      "out.shape torch.Size([204, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -125.806640625, -5.695598627441317, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 128.71875, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': -4.5}\n",
      "torch.Size([218, 70]) torch.Size([10, 218])\n",
      "out.shape torch.Size([218, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -119.4033203125, -5.695598627441317, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 157.859375, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'2': -56.5, '11': 93.5}\n",
      "torch.Size([137, 70]) torch.Size([10, 137])\n",
      "out.shape torch.Size([137, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([137, 70]) torch.Size([10, 137])\n",
      "out.shape torch.Size([137, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -119.4033203125, -0.3559749142150823, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 157.859375, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([294, 70]) torch.Size([10, 294])\n",
      "out.shape torch.Size([294, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -119.4033203125, -0.022248432138442645, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 157.859375, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([781, 70]) torch.Size([10, 781])\n",
      "out.shape torch.Size([781, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -119.4033203125, -0.0013905270086526653, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 157.859375, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([307, 70]) torch.Size([10, 307])\n",
      "out.shape torch.Size([307, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -119.4033203125, -3.1875054317461275, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 157.859375, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': -3.1875}\n",
      "torch.Size([279, 70]) torch.Size([10, 279])\n",
      "out.shape torch.Size([279, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -119.4033203125, -9.199219089484133, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 157.859375, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': -9.0}\n",
      "torch.Size([160, 70]) torch.Size([10, 160])\n",
      "out.shape torch.Size([160, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -119.4033203125, -27.770702362392072, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 157.859375, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': -27.76171875}\n",
      "torch.Size([345, 70]) torch.Size([10, 345])\n",
      "out.shape torch.Size([345, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -119.4033203125, -1.7356688976495045, -9.02294921875, -77.25, -87.75, 0, 131.9921875, -57.0, -107.625, 157.859375, 42.84375, 45.380859375, 144.826171875, -54.5, 17.25, -38.3125, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([259, 70]) torch.Size([10, 259])\n",
      "out.shape torch.Size([259, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -98.70166015625, -1.7356688976495045, -84.511474609375, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, 42.84375, 45.380859375, 144.826171875, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'2': -39.0, '4': -80.0, '6': 0.5, '11': 111.5, '16': -10.5, '17': 39.0}\n",
      "torch.Size([641, 70]) torch.Size([10, 641])\n",
      "out.shape torch.Size([641, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([641, 70]) torch.Size([10, 641])\n",
      "out.shape torch.Size([641, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([641, 70]) torch.Size([10, 641])\n",
      "out.shape torch.Size([641, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([641, 70]) torch.Size([10, 641])\n",
      "out.shape torch.Size([641, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([641, 70]) torch.Size([10, 641])\n",
      "out.shape torch.Size([641, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([641, 70]) torch.Size([10, 641])\n",
      "out.shape torch.Size([641, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -98.70166015625, 52.01652069389691, -84.511474609375, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, 42.84375, 45.380859375, 144.826171875, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'3': 52.125}\n",
      "torch.Size([953, 70]) torch.Size([10, 953])\n",
      "out.shape torch.Size([953, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -98.70166015625, 0.4063790679210696, -84.511474609375, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, 42.84375, 45.380859375, 144.826171875, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([169, 70]) torch.Size([10, 169])\n",
      "out.shape torch.Size([169, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -98.70166015625, 0.012699345872533425, -84.511474609375, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, 42.84375, 45.380859375, 144.826171875, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([203, 70]) torch.Size([10, 203])\n",
      "out.shape torch.Size([203, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -98.70166015625, -29.811706290882967, -84.511474609375, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, 42.84375, 45.380859375, 144.826171875, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'3': -29.8125}\n",
      "torch.Size([172, 70]) torch.Size([10, 172])\n",
      "out.shape torch.Size([172, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -98.70166015625, -182.9882316431802, -84.511474609375, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, 42.84375, 45.380859375, 144.826171875, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'3': -181.125}\n",
      "torch.Size([285, 70]) torch.Size([10, 285])\n",
      "out.shape torch.Size([285, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -98.70166015625, -182.9882316431802, 39.7442626953125, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, 73.921875, 7.1904296875, 109.4130859375, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'4': 82.0, '12': 52.5, '13': -15.5, '14': 37.0}\n",
      "torch.Size([59, 70]) torch.Size([10, 59])\n",
      "out.shape torch.Size([59, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([59, 70]) torch.Size([10, 59])\n",
      "out.shape torch.Size([59, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([59, 70]) torch.Size([10, 59])\n",
      "out.shape torch.Size([59, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([59, 70]) torch.Size([10, 59])\n",
      "out.shape torch.Size([59, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -98.70166015625, -182.9882316431802, -145.12786865234375, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, 73.921875, 7.1904296875, 109.4130859375, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'4': -165.0}\n",
      "torch.Size([157, 70]) torch.Size([10, 157])\n",
      "out.shape torch.Size([157, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, -182.9882316431802, -145.12786865234375, -77.25, -43.375, 0, 131.9921875, -57.0, -107.625, 190.4296875, -95.5390625, 7.1904296875, 109.4130859375, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'2': -3.5, '12': -132.5}\n",
      "torch.Size([145, 70]) torch.Size([10, 145])\n",
      "out.shape torch.Size([145, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([145, 70]) torch.Size([10, 145])\n",
      "out.shape torch.Size([145, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, -182.9882316431802, -85.06393432617188, -77.25, -43.375, 0, 57.49609375, -57.0, -107.625, 190.4296875, 7.23046875, 7.1904296875, 47.20654296875, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'4': -12.5, '8': -8.5, '12': 55.0, '14': -7.5}\n",
      "torch.Size([55, 70]) torch.Size([10, 55])\n",
      "out.shape torch.Size([55, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([55, 70]) torch.Size([10, 55])\n",
      "out.shape torch.Size([55, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([55, 70]) torch.Size([10, 55])\n",
      "out.shape torch.Size([55, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([55, 70]) torch.Size([10, 55])\n",
      "out.shape torch.Size([55, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, -91.4941158215901, -85.06393432617188, -77.25, -43.375, 0, 57.49609375, -57.0, -107.625, 190.4296875, 7.23046875, 7.1904296875, 47.20654296875, -54.5, -1.875, 19.84375, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([139, 70]) torch.Size([10, 139])\n",
      "out.shape torch.Size([139, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, -91.4941158215901, -45.03196716308594, -77.25, 128.3125, 0, 57.49609375, -57.0, -107.625, 190.4296875, 72.115234375, 153.59521484375, 153.103271484375, -54.5, -1.875, 11.421875, -104.8125]\n",
      "{'4': -2.5, '6': 150.0, '12': 68.5, '13': 150.0, '14': 129.5, '17': 1.5}\n",
      "torch.Size([106, 70]) torch.Size([10, 106])\n",
      "out.shape torch.Size([106, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([106, 70]) torch.Size([10, 106])\n",
      "out.shape torch.Size([106, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([106, 70]) torch.Size([10, 106])\n",
      "out.shape torch.Size([106, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([106, 70]) torch.Size([10, 106])\n",
      "out.shape torch.Size([106, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([106, 70]) torch.Size([10, 106])\n",
      "out.shape torch.Size([106, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([106, 70]) torch.Size([10, 106])\n",
      "out.shape torch.Size([106, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, -45.74705791079505, -45.03196716308594, -77.25, 128.3125, 0, 57.49609375, -57.0, -107.625, 190.4296875, 72.115234375, 153.59521484375, 153.103271484375, -54.5, -1.875, 11.421875, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([134, 70]) torch.Size([10, 134])\n",
      "out.shape torch.Size([134, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, 29.64080888057531, -45.03196716308594, -77.25, 128.3125, 0, 57.49609375, -57.0, -107.625, 190.4296875, 72.115234375, 153.59521484375, 153.103271484375, -54.5, -1.875, 11.421875, -104.8125]\n",
      "{'3': 32.5}\n",
      "torch.Size([438, 70]) torch.Size([10, 438])\n",
      "out.shape torch.Size([438, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, 181.40484690968975, -45.03196716308594, -77.25, 128.3125, 0, 57.49609375, -57.0, -107.625, 190.4296875, 72.115234375, 153.59521484375, 153.103271484375, -54.5, -1.875, 11.421875, -104.8125]\n",
      "{'3': 181.2890625}\n",
      "torch.Size([294, 70]) torch.Size([10, 294])\n",
      "out.shape torch.Size([294, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, 2.8344507329639024, -45.03196716308594, -77.25, 128.3125, 0, 57.49609375, -57.0, -107.625, 190.4296875, 72.115234375, 153.59521484375, 153.103271484375, -54.5, -1.875, 11.421875, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([150, 70]) torch.Size([10, 150])\n",
      "out.shape torch.Size([150, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, 2.8344507329639024, -45.03196716308594, -77.25, -25.84375, 0, 57.49609375, -57.0, -107.625, 190.4296875, 63.5576171875, 153.59521484375, 69.0516357421875, -54.5, -1.875, 6.2109375, -104.8125]\n",
      "{'6': -90.0, '12': 27.5, '14': -7.5, '17': 0.5}\n",
      "torch.Size([122, 70]) torch.Size([10, 122])\n",
      "out.shape torch.Size([122, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([122, 70]) torch.Size([10, 122])\n",
      "out.shape torch.Size([122, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([122, 70]) torch.Size([10, 122])\n",
      "out.shape torch.Size([122, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([122, 70]) torch.Size([10, 122])\n",
      "out.shape torch.Size([122, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, 0.7086126832409756, -45.03196716308594, -77.25, -25.84375, 0, 57.49609375, -57.0, -107.625, 190.4296875, 63.5576171875, 153.59521484375, 69.0516357421875, -54.5, -1.875, 6.2109375, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([290, 70]) torch.Size([10, 290])\n",
      "out.shape torch.Size([290, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, 23.41928829270256, -45.03196716308594, -77.25, -25.84375, 0, 57.49609375, -57.0, -107.625, 190.4296875, 63.5576171875, 153.59521484375, 69.0516357421875, -54.5, -1.875, 6.2109375, -104.8125]\n",
      "{'3': 23.375}\n",
      "torch.Size([408, 70]) torch.Size([10, 408])\n",
      "out.shape torch.Size([408, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -52.850830078125, 0.022870398723342344, -45.03196716308594, -77.25, -25.84375, 0, 57.49609375, -57.0, -107.625, 190.4296875, 63.5576171875, 153.59521484375, 69.0516357421875, -54.5, -1.875, 6.2109375, -104.8125]\n",
      "{'3': 0.0}\n",
      "torch.Size([301, 70]) torch.Size([10, 301])\n",
      "out.shape torch.Size([301, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -176.4254150390625, 0.022870398723342344, -74.01598358154297, -77.25, -25.84375, 0, 42.248046875, -57.0, -52.3125, 80.21484375, 90.27880859375, 153.59521484375, 48.02581787109375, -54.5, -1.875, 6.2109375, -50.90625]\n",
      "{'2': -150.0, '4': -51.5, '8': 13.5, '10': 1.5, '11': -15.0, '12': 58.5, '14': 13.5, '18': 1.5}\n",
      "torch.Size([610, 70]) torch.Size([10, 610])\n",
      "out.shape torch.Size([610, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([610, 70]) torch.Size([10, 610])\n",
      "out.shape torch.Size([610, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([610, 70]) torch.Size([10, 610])\n",
      "out.shape torch.Size([610, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([610, 70]) torch.Size([10, 610])\n",
      "out.shape torch.Size([610, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([610, 70]) torch.Size([10, 610])\n",
      "out.shape torch.Size([610, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([610, 70]) torch.Size([10, 610])\n",
      "out.shape torch.Size([610, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([610, 70]) torch.Size([10, 610])\n",
      "out.shape torch.Size([610, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([610, 70]) torch.Size([10, 610])\n",
      "out.shape torch.Size([610, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -176.4254150390625, 100.68892939992021, -74.01598358154297, -77.25, -25.84375, 0, 42.248046875, -57.0, -52.3125, 80.21484375, 90.27880859375, 153.59521484375, 48.02581787109375, -54.5, -1.875, 6.2109375, -50.90625]\n",
      "{'3': 100.6875}\n",
      "torch.Size([309, 70]) torch.Size([10, 309])\n",
      "out.shape torch.Size([309, 1, 53760])\n",
      "torch.Size([19])\n",
      "[0, -7.5, -238.21270751953125, 100.68892939992021, -25.507991790771484, -77.25, -25.84375, 0, 38.1240234375, -57.0, -17.65625, 25.107421875, 103.639404296875, 93.797607421875, 40.012908935546875, -54.5, 23.0625, 6.2109375, -16.953125]\n",
      "{'2': -150.0, '4': 11.5, '8': 17.0, '10': 8.5, '11': -15.0, '12': 58.5, '13': 17.0, '14': 16.0, '16': 24.0, '18': 8.5}\n",
      "torch.Size([883, 70]) torch.Size([10, 883])\n",
      "out.shape torch.Size([883, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([883, 70]) torch.Size([10, 883])\n",
      "out.shape torch.Size([883, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([883, 70]) torch.Size([10, 883])\n",
      "out.shape torch.Size([883, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([883, 70]) torch.Size([10, 883])\n",
      "out.shape torch.Size([883, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([883, 70]) torch.Size([10, 883])\n",
      "out.shape torch.Size([883, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([883, 70]) torch.Size([10, 883])\n",
      "out.shape torch.Size([883, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([883, 70]) torch.Size([10, 883])\n",
      "out.shape torch.Size([883, 1, 53760])\n",
      "torch.Size([19])\n",
      "torch.Size([883, 70]) torch.Size([10, 883])\n",
      "out.shape torch.Size([883, 1, 53760])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 12153244672 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Temp\\ipykernel_19056\\1454240714.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data_requests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_data_date\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_data_requests\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_data_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Temp\\ipykernel_19056\\4052637591.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, in_data_cat, in_data_request, in_data_date)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_data_cat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_data_request\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_data_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# proccess request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mout_req\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data_request\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_data_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m#out_req, (hid, cell) = self.rnn(out_req)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# concatenate information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Temp\\ipykernel_19056\\801700436.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, in_data, in_data_2)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m         return F.max_pool1d(input, self.kernel_size, self.stride,\n\u001b[0;32m     93\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m                             return_indices=self.return_indices)\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool1d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 12153244672 bytes."
     ]
    }
   ],
   "source": [
    "dataset = CustomDataset(table_1, table_2, table_3, padded)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=1)\n",
    "X_batch = []\n",
    "y_batch = []\n",
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "c = 0\n",
    "train_epoch_loss = []\n",
    "val_epoch_loss = []\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for x,y in dataloader:\n",
    "        for count, x_batch in enumerate(X_batch):\n",
    "            y = compute_y(x_batch[2])\n",
    "            print(y)\n",
    "            for work_id in y.keys():\n",
    "                data_request = x_batch[3] #данные по заявкам\n",
    "                data_add_for_first_model = get_data_date(x_batch[1]) # данные времени по заявкам\n",
    "                data_mlh = x_batch[0] # хар-ки дома\n",
    "                number_work = float(work_id) # номер работы\n",
    "                y_true = y[work_id]\n",
    "\n",
    "                #in_data_cat - категориальные признаки + дата окончания последнего кап ремонта\n",
    "                in_data_cat = torch.cat((torch.tensor(data_mlh), torch.tensor([int(work_id)])))\n",
    "\n",
    "                # in_data_requests - заявки по данному уному\n",
    "                in_data_requests = torch.tensor(data_request)\n",
    "                # in_data_date - данные о времени заявок\n",
    "                in_data_date = torch.tensor(data_add_for_first_model)\n",
    "                print(in_data_requests.size(), in_data_date.size())\n",
    "\n",
    "                preds = model(in_data_cat, in_data_requests, in_data_date)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss = loss_fn(torch.tensor([y_true]), preds)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "                train_loss.append(loss)\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "    train_loss.append(sum(train_loss)/len(train_loss))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"predict_dev.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(checkpoint_path, model, optimizer):\n",
    "    # state_dict: a Python dictionary object that:\n",
    "    # - for a model, maps each layer to its parameter tensor;\n",
    "    # - for an optimizer, contains info about the optimizer’s states and hyperparameters used.\n",
    "    state = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer' : optimizer.state_dict()}\n",
    "    torch.save(state, checkpoint_path)\n",
    "    print('model saved to %s' % checkpoint_path)\n",
    "    \n",
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    state = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    optimizer.load_state_dict(state['optimizer'])\n",
    "    print('model loaded from %s' % checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved to predict_dev.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from predict_dev.pth\n"
     ]
    }
   ],
   "source": [
    "# create a new model\n",
    "save_checkpoint(\"predict_dev.pth\", model, opt)\n",
    "model = model = ComputeResultNN(num_features_req=NUM_FEATURES_REQ,\n",
    "                        num_features_cat=14,\n",
    "                        num_output=19,\n",
    "                        num_add_features=10,\n",
    "                        num_features_date_cup=7)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# load from the final checkpoint\n",
    "load_checkpoint(\"predict_dev.pth\", model, opt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padded(table_2, maxl_len=70):\n",
    "    #BERT tokenizer\n",
    "    model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    # удаление нахер вссего NaN дерьма\n",
    "    for count, elem in enumerate(table_2[\"Наименование\"].isna()):\n",
    "        if elem:\n",
    "            table_2 = table_2.drop(labels=[count], axis=0)\n",
    "    table_2[\"Наименование\"].isna().sum()\n",
    "\n",
    "    # apply tokenizator\n",
    "    df = table_2[\"Наименование\"].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "    # find max_len\n",
    "    max_len = 0\n",
    "    for i in df.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "\n",
    "    if max_len % 2 == 1:\n",
    "        max_len += 1\n",
    "\n",
    "    # add <pad> symbol\n",
    "    padded = np.array([i + [0]*(max_len-len(i)) for i in df.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_data_cat - категориальные признаки + дата окончания последнего кап ремонта (14 штук)\n",
    "# in_data_requests - заявки по данному уному (заявки по уному в виде таблицы)\n",
    "# in_data_date - данные о времени заявок (3 т)\n",
    "def get_result(table_1, table_2, table_3, model):\n",
    "    model.train(False)\n",
    "    result = {}\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    padded = get_padded(table_2)\n",
    "    dataset = CustomDataset(table_1, table_2, table_3, padded)\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=1)\n",
    "    for x,_ in dataloader:\n",
    "        for count, x_batch in enumerate(X_batch):\n",
    "            y = compute_y(x_batch[2])\n",
    "            print(y)\n",
    "            for work_id in y.keys():\n",
    "                data_request = x_batch[3] #данные по заявкам\n",
    "                data_add_for_first_model = get_data_date(x_batch[1]) # данные времени по заявкам\n",
    "                data_mlh = x_batch[0] # хар-ки дома\n",
    "                number_work = float(work_id) # номер работы\n",
    "                y_true = y[work_id]\n",
    "\n",
    "                #in_data_cat - категориальные признаки + дата окончания последнего кап ремонта\n",
    "                in_data_cat = torch.cat((torch.tensor(data_mlh), torch.tensor([int(work_id)])))\n",
    "\n",
    "                # in_data_requests - заявки по данному уному\n",
    "                in_data_requests = torch.tensor(data_request)\n",
    "                # in_data_date - данные о времени заявок\n",
    "                in_data_date = torch.tensor(data_add_for_first_model)\n",
    "\n",
    "                preds = model(in_data_cat, in_data_requests, in_data_date)\n",
    "\n",
    "                result[work_id] = preds\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_training(table_1, table_2, table_3, opt, model):\n",
    "    model.train(True)\n",
    "    loss_fn = nn.L1Loss()\n",
    "    padded = get_padded(table_2)\n",
    "    dataset = CustomDataset(table_1, table_2, table_3, padded)\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=1)\n",
    "    for x,_ in dataloader:\n",
    "        for count, x_batch in enumerate(X_batch):\n",
    "            y = compute_y(x_batch[2])\n",
    "            print(y)\n",
    "            for work_id in y.keys():\n",
    "                data_request = x_batch[3] #данные по заявкам\n",
    "                data_add_for_first_model = get_data_date(x_batch[1]) # данные времени по заявкам\n",
    "                data_mlh = x_batch[0] # хар-ки дома\n",
    "                number_work = float(work_id) # номер работы\n",
    "                y_true = y[work_id]\n",
    "\n",
    "                #in_data_cat - категориальные признаки + дата окончания последнего кап ремонта\n",
    "                in_data_cat = torch.cat((torch.tensor(data_mlh), torch.tensor([int(work_id)])))\n",
    "\n",
    "                # in_data_requests - заявки по данному уному\n",
    "                in_data_requests = torch.tensor(data_request)\n",
    "                # in_data_date - данные о времени заявок\n",
    "                in_data_date = torch.tensor(data_add_for_first_model)\n",
    "\n",
    "                preds = model(in_data_cat, in_data_requests, in_data_date)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                loss = loss_fn(torch.tensor(y_true), preds)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "    model.train(False)\n",
    "    return model, opt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
